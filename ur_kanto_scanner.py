import asyncio
from playwright.async_api import async_playwright
import re
import requests
from datetime import datetime
import os
from dotenv import load_dotenv

load_dotenv()

# --- é…ç½® (è¯·ç¡®ä¿ token å’Œ ID æ­£ç¡®) ---
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
DATABASE_ID = os.getenv("DATABASE_ID")
MAX_PRICE = 160000
AREAS = ["tokyo", "kanagawa", "chiba"]

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# å…¨å±€å˜é‡ï¼šç”¨äºå­˜å‚¨æ•°æ®åº“ç°æœ‰æˆ¿æºï¼Œå®ç°åŠ é€Ÿæ¯”å¯¹å’Œä¸‹æ¶æ£€æµ‹
# æ ¼å¼: { "url": {"page_id": "xxx", "price": 123} }
existing_pages_map = {}

def call_notion_api(method, url, data=None):
    try:
        if method == "POST":
            response = requests.post(url, headers=HEADERS, json=data)
        elif method == "PATCH":
            response = requests.patch(url, headers=HEADERS, json=data)
        
        if response.status_code not in [200, 201]:
            print(f"âŒ Notion API é”™è¯¯ ({response.status_code}): {response.text}")
            return None
        return response.json()
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
        return None

async def fetch_all_existing_pages():
    """ç¨‹åºå¯åŠ¨æ—¶ï¼Œä¸€æ¬¡æ€§è·å–æ•°æ®åº“æ‰€æœ‰æˆ¿æºçš„ URL å’Œä»·æ ¼"""
    global existing_pages_map
    print("ğŸ“¡ æ­£åœ¨åŒæ­¥ Notion æ•°æ®åº“ç°çŠ¶...")
    query_url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    
    has_more = True
    next_cursor = None
    
    while has_more:
        payload = {"page_size": 100}
        if next_cursor:
            payload["start_cursor"] = next_cursor
            
        res = call_notion_api("POST", query_url, payload)
        if not res: break
        
        for page in res.get("results", []):
            url_prop = page["properties"].get("é“¾æ¥", {}).get("url")
            price_prop = page["properties"].get("ç§Ÿé‡‘", {}).get("number")
            name_list = page["properties"].get("æˆ¿æºåç§°", {}).get("title", [])
            name_text = name_list[0].get("plain_text", "æœªçŸ¥æˆ¿æº") if name_list else "æœªçŸ¥æˆ¿æº"
            status_prop = page["properties"].get("æˆ¿å±‹çŠ¶æ€", {}).get("status", {}).get("name") 

            if url_prop:
                existing_pages_map[url_prop] = {
                    "page_id": page["id"],
                    "price": price_prop,
                    "name": name_text,
                    "status": status_prop
                }
        
        has_more = res.get("has_more")
        next_cursor = res.get("next_cursor")
    
    print(f"âœ… åŒæ­¥å®Œæˆï¼Œåº“ä¸­ç°æœ‰ {len(existing_pages_map)} æ¡æˆ¿æºã€‚")

async def scrape_room_details(page, detail_url, seen_urls):
    """
    seen_urls: æœ¬æ¬¡çˆ¬è™«è¿è¡Œä¸­è§åˆ°çš„æ‰€æœ‰ URL é›†åˆ
    """
    try:
        seen_urls.add(detail_url) # è®°å½•æ­¤ URL ä¾ç„¶å­˜æ´»
        
        await page.goto(detail_url, wait_until="domcontentloaded")
        await page.wait_for_selector(".roomprice_body_emphasis", timeout=10000)
        
        rent_text = await page.eval_on_selector(".roomprice_body_emphasis", "el => el.innerText")
        current_price = int(''.join(re.findall(r'\d+', rent_text)))
        
        if current_price > MAX_PRICE:
            return False
        
        async def get_coords(p):
            return await p.evaluate('''() => {
                const latEl = document.querySelector(".js-lat-data");
                const lngEl = document.querySelector(".js-lng-data");
                return latEl && lngEl ? { lat: latEl.value, lng: lngEl.value } : null;
            }''')

        coords = await get_coords(page)

        now = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")

        # --- æ ¸å¿ƒé€»è¾‘ï¼šä½¿ç”¨æœ¬åœ° Map è¿›è¡Œæ¯”å¯¹ ---
        if detail_url in existing_pages_map:
            page_info = existing_pages_map[detail_url]
            page_id = page_info["page_id"]
            old_price = page_info["price"]
            old_status = page_info.get("status")
            existing_name = page_info["name"]

            update_properties = {}

            if old_status == "å·²ä¸‹çº¿":
                update_properties["æˆ¿å±‹çŠ¶æ€"] = {"status": {"name": "ç©ºå®¤å¯ç§Ÿ"}}
                update_properties["æˆ‘çš„çŠ¶æ€"] = {"status": {"name": "å¾…ç­›é€‰"}} # å¯é€‰ï¼šå¤æ´»åé‡æ–°æé†’ç­›é€‰
                print(f"    ğŸ”¥ [æˆ¿æºå¤æ´»]: {existing_name} é‡æ–°ä¸Šçº¿äº†ï¼")

            if current_price != old_price:
                update_properties["ç§Ÿé‡‘"] = {"number": current_price}
                update_properties["æ›´æ–°æ—¶é—´"] = {"date": {"start": now}}
                print(f"    ğŸ†™ [ä»·æ ¼å˜åŠ¨]: {existing_name} ï¿¥{old_price}->ï¿¥{current_price}")

            if update_properties:
                # ç¡®ä¿åŒ…å«æ›´æ–°æ—¶é—´
                if "æ›´æ–°æ—¶é—´" not in update_properties:
                    update_properties["æ›´æ–°æ—¶é—´"] = {"date": {"start": now}}
                call_notion_api("PATCH", f"https://api.notion.com/v1/pages/{page_id}", {"properties": update_properties})
            else:
                # æ— å˜åŠ¨ï¼Œä»…é™é»˜æ›´æ–°æ´»è·ƒæ—¶é—´
                call_notion_api("PATCH", f"https://api.notion.com/v1/pages/{page_id}", 
                                {"properties": {"æ›´æ–°æ—¶é—´": {"date": {"start": now}}}})
                print(f"    ğŸ˜´ [ä¿æŒç°çŠ¶]: {existing_name}")
            
            return True

        # --- æ–°æˆ¿æºé€»è¾‘ ---
        # (å­—æ®µæŠ“å–é€»è¾‘ä¿æŒä¸å˜...)
        area_el = await page.query_selector(".item_subtitle")
        area_name = re.sub(r'\(.*?\).*', '', (await area_el.inner_text()).split('\n')[0]).strip() if area_el else "UR"
        room_el = await page.query_selector(".item_title.rep_room-nm") or await page.query_selector(".item_title")
        room_no = (await room_el.inner_text()).replace('æœ€è¿‘è¦‹ãŸéƒ¨å±‹', '').strip() if room_el else ""
        full_title = f"{area_name} {room_no}".strip()

        price_area = await page.locator(".roomprice_item, li.roomprice, .roomprice_body").first.inner_text()
        fee_match = re.search(r'\((\d+,?\d+)å††\)', price_area)
        fee = int(fee_match.group(1).replace(',', '')) if fee_match else 0
        
        layout_size_el = await page.query_selector(".rep_madori-yuka")
        layout_size_text = (await layout_size_el.inner_text()).strip() if layout_size_el else ""
        room_type, size_text = ("å¾…ç¡®è®¤", "æœªçŸ¥")
        if "/" in layout_size_text:
            parts = layout_size_text.split("/")
            room_type, size_text = parts[0].strip(), parts[1].strip()

        floor_el = await page.query_selector(".rep_kai")
        floor_text = (await floor_el.inner_text()).strip() if floor_el else "æœªçŸ¥"
        years_el = await page.query_selector(".rep_years")
        years_text = (await years_el.inner_text()).strip() if years_el else "æœªçŸ¥"

        if not coords:
            map_url = detail_url.replace("_room.html", "_room_map.html")
            print(f"    ğŸ”„ ä¸»é¡µæœªæ‰¾åˆ°åæ ‡ï¼Œå°è¯•è·³è½¬åœ°å›¾é¡µ: {map_url}")
            await page.goto(map_url, wait_until="domcontentloaded")
            # åœ¨åœ°å›¾é¡µç»™ä¸€ç‚¹ç¼“å†²æ—¶é—´
            await page.wait_for_timeout(1000)
            coords = await get_coords(page)

        if coords:
            lat_num = float(coords['lat'])
            lng_num = float(coords['lng'])
            print(f"    ğŸ“ åæ ‡æŠ“å–æˆåŠŸ: {lat_num}, {lng_num}")
        else:
            print(f"    âš ï¸ æœ€ç»ˆæœªèƒ½æ‰¾åˆ°åæ ‡æ ‡ç­¾")
            lat_num, lng_num = 0.0, 0.0

        props = {
            "æˆ¿æºåç§°": {"title": [{"text": {"content": full_title}}]},
            "ç§Ÿé‡‘": {"number": current_price},
            "ç®¡ç†è´¹": {"number": fee},
            "çº¬åº¦": {"number": lat_num}, 
            "ç»åº¦": {"number": lng_num},
            "é¢ç§¯": {"rich_text": [{"text": {"content": size_text}}]},
            "æ€»è´¹ç”¨": {"number": current_price + fee},
            "æˆ‘çš„çŠ¶æ€": {"status": {"name": "å¾…ç­›é€‰"}},
            "æ¥¼å±‚": {"rich_text": [{"text": {"content": floor_text}}]},
            "æˆ¿å‹": {"select": {"name": room_type}},
            "ç®¡ç†å¹´ä»½": {"rich_text": [{"text": {"content": years_text}}]},
            "æ›´æ–°æ—¶é—´": {"date": {"start": now}},
            "é“¾æ¥": {"url": detail_url},
            "æˆ¿å±‹çŠ¶æ€": {"status": {"name": "ç©ºå®¤å¯ç§Ÿ"}},
        }
        
        if call_notion_api("POST", "https://api.notion.com/v1/pages", {"parent": {"database_id": DATABASE_ID}, "properties": props}):
            print(f"    âœ¨ [æ–°å½•å…¥]: {full_title}")
            return True
            
    except Exception as e:
        print(f"    âš ï¸ æŠ“å–å¤±è´¥: {e}")
    return False

async def main():
    # 1. åˆå§‹åŒ–æ•°æ®åº“å¿«ç…§
    await fetch_all_existing_pages()
    
    # æœ¬æ¬¡è§åˆ°çš„æ‰€æœ‰ URL é›†åˆ
    seen_urls = set()

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()

        for area_code in AREAS:
            print(f"\nğŸŒ === æ­£åœ¨å¼€å§‹æŠ“å–åœ°åŒº: {area_code.upper()} ===")
            await page.goto(f"https://www.ur-net.go.jp/chintai/kanto/{area_code}/area/")
            await page.evaluate("""() => {
                document.querySelectorAll("input[type='checkbox']:not(:disabled)").forEach(b => {
                    b.checked = true;
                    b.dispatchEvent(new Event('change', { bubbles: true }));
                });
            }""")
            await page.wait_for_timeout(2000)
            await page.goto(f"https://www.ur-net.go.jp/chintai/kanto/{area_code}/result/")

            page_num = 1
            while True:
                print(f"--- ğŸ“„ {area_code.upper()} æ­£åœ¨æ‰«æç¬¬ {page_num} é¡µ ---")
                try:
                    await page.wait_for_selector("a:has-text('éƒ¨å±‹è©³ç´°')", timeout=15000)
                except:
                    break

                links = [f"https://www.ur-net.go.jp{await btn.get_attribute('href')}" 
                         for btn in await page.query_selector_all("a:has-text('éƒ¨å±‹è©³ç´°')")]
                
                detail_page = await context.new_page()
                for link in links:
                    await scrape_room_details(detail_page, link, seen_urls)
                await detail_page.close()

                # ç¿»é¡µé€»è¾‘
                next_btn = await page.query_selector("li.next a, a:has-text('æ¬¡ã¸')")
                if next_btn and await next_btn.is_visible():
                    page_num += 1
                    await next_btn.click()
                    await page.wait_for_timeout(4000)
                else: break

        await browser.close()

    # 3. æ ‡è®°ä¸‹æ¶æˆ¿æº
    print("\nğŸ§¹ æ­£åœ¨æ£€æŸ¥å¹¶æ›´æ–°å·²ä¸‹æ¶æˆ¿æºçŠ¶æ€...")
    deleted_count = 0
    for url, info in existing_pages_map.items():
        if url not in seen_urls and info.get("status") != "å·²ä¸‹çº¿":
            # è¯¥æˆ¿æºåœ¨æ•°æ®åº“é‡Œæœ‰ï¼Œä½†æœ¬æ¬¡éå†ç½‘é¡µæ²¡æŠ“åˆ° -> è¯´æ˜å·²ä¸‹æ¶
            # ä¸å†åˆ é™¤ï¼Œè€Œæ˜¯å°†â€œæˆ‘çš„çŠ¶æ€â€æ›´æ–°ä¸ºâ€œå·²ä¸‹çº¿â€
            update_data = {
                "properties": {
                    "æˆ¿å±‹çŠ¶æ€": {"status": {"name": "å·²ä¸‹çº¿"}}
                }
            }
            # å¦‚æœä½ å¸Œæœ›åŒæ—¶æ¸…ç©ºç§Ÿé‡‘æˆ–è€…æ›´æ–°æ—¶é—´ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
            call_notion_api("PATCH", f"https://api.notion.com/v1/pages/{info['page_id']}", update_data)
            deleted_count += 1
            print(f"    ğŸ’¤ [æˆ¿æºä¸‹çº¿]: {info['name']} ({url})")
    
    print(f"\nğŸ‰ ä»»åŠ¡åœ†æ»¡å®Œæˆï¼æ–°å¢/æ›´æ–°å®Œæ¯•ï¼Œå¹¶æ ‡è®°äº† {deleted_count} æ¡å·²ä¸‹çº¿æ•°æ®ã€‚")

if __name__ == "__main__":
    asyncio.run(main())